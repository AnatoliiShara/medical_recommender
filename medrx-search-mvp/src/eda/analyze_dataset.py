#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ê–Ω–∞–ª—ñ–∑ –º–µ–¥–∏—á–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É - –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω—å —Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ –¥–∞–Ω–∏—Ö
"""

import pandas as pd
import os
from pathlib import Path
import sys

def analyze_dataset():
    """–ê–Ω–∞–ª—ñ–∑—É—î —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–µ–¥–∏—á–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É"""
    
    print("üîç –ê–ù–ê–õ–Ü–ó –ú–ï–î–ò–ß–ù–û–ì–û –î–ê–¢–ê–°–ï–¢–£")
    print("=" * 50)
    
    # –ú–æ–∂–ª–∏–≤—ñ —à–ª—è—Ö–∏ –¥–æ –¥–∞—Ç–∞—Å–µ—Ç—É
    data_paths = [
        "data/processed/clean_medical.parquet",
        "data/raw/compendium_all.parquet",
        "data/processed/clean_medical_demo.parquet",
        "../data/processed/clean_medical.parquet",
        "../data/raw/compendium_all.parquet"
    ]
    
    found_datasets = []
    
    # –ü–æ—à—É–∫ –¥–∞—Ç–∞—Å–µ—Ç—ñ–≤
    for path in data_paths:
        if os.path.exists(path):
            found_datasets.append(path)
            print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ: {path}")
        else:
            print(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {path}")
    
    if not found_datasets:
        print("\n‚ùå –î–ê–¢–ê–°–ï–¢–ò –ù–ï –ó–ù–ê–ô–î–ï–ù–û!")
        print("–ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —á–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∫–∞–∑–∞–Ω—ñ —à–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤")
        
        # –°–ø—Ä–æ–±—É—î–º–æ –∑–Ω–∞–π—Ç–∏ –≤—Å—ñ .parquet —Ñ–∞–π–ª–∏
        print("\nüîç –ü–æ—à—É–∫ –≤—Å—ñ—Ö .parquet —Ñ–∞–π–ª—ñ–≤:")
        for root, dirs, files in os.walk("."):
            for file in files:
                if file.endswith(".parquet"):
                    full_path = os.path.join(root, file)
                    file_size = os.path.getsize(full_path) / 1024 / 1024  # MB
                    print(f"   üìÅ {full_path} ({file_size:.1f} MB)")
        
        return
    
    # –ê–Ω–∞–ª—ñ–∑ –∫–æ–∂–Ω–æ–≥–æ –∑–Ω–∞–π–¥–µ–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É
    for i, path in enumerate(found_datasets):
        print(f"\n{'='*60}")
        print(f"üìä –ê–ù–ê–õ–Ü–ó –î–ê–¢–ê–°–ï–¢–£ #{i+1}: {path}")
        print(f"{'='*60}")
        
        try:
            # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É
            print("üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –¥–∞—Ç–∞—Å–µ—Ç...")
            df = pd.read_parquet(path)
            
            # –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è
            print(f"üìà –ó–∞–≥–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤: {len(df):,}")
            print(f"üìã –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
            
            file_size = os.path.getsize(path) / 1024 / 1024  # MB
            print(f"üíæ –†–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É: {file_size:.1f} MB")
            
            # –ü–æ–∫–∞–∑–∞—Ç–∏ –≤—Å—ñ –∫–æ–ª–æ–Ω–∫–∏
            print(f"\nüìã –í–°–Ü –ö–û–õ–û–ù–ö–ò ({len(df.columns)}):")
            for j, col in enumerate(df.columns):
                non_null = df[col].notna().sum()
                percentage = (non_null / len(df)) * 100
                print(f"   {j:2d}. {col:<30} | –ó–∞–ø–æ–≤–Ω–µ–Ω–æ: {non_null:>6,} ({percentage:5.1f}%)")
            
            # –ü–æ—à—É–∫ –∫–æ–ª–æ–Ω–æ–∫ –∑ –ø—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è–º–∏
            print(f"\nüîç –ü–û–®–£–ö –ü–†–û–¢–ò–ü–û–ö–ê–ó–ê–ù–¨:")
            contraindication_keywords = [
                '–ø—Ä–æ—Ç–∏–ø–æ–∫–∞–∑', 'contraind', '–ø–æ–±—ñ—á–Ω', 'side_effect', 
                'warning', '–ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω', '–æ–±–º–µ–∂–µ–Ω', 'restriction'
            ]
            
            contraindication_cols = []
            for col in df.columns:
                col_lower = col.lower()
                for keyword in contraindication_keywords:
                    if keyword in col_lower:
                        contraindication_cols.append(col)
                        break
            
            if contraindication_cols:
                print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(contraindication_cols)} –∫–æ–ª–æ–Ω–∫–∏ –∑ –ø—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è–º–∏:")
                
                for col in contraindication_cols:
                    non_null = df[col].notna().sum()
                    percentage = (non_null / len(df)) * 100
                    print(f"\n   üìã –ö–æ–ª–æ–Ω–∫–∞: '{col}'")
                    print(f"   üìä –ó–∞–ø–æ–≤–Ω–µ–Ω–æ: {non_null:,} –∑–∞–ø–∏—Å—ñ–≤ ({percentage:.1f}%)")
                    
                    # –ü–æ–∫–∞–∑–∞—Ç–∏ –ø—Ä–∏–∫–ª–∞–¥–∏ –¥–∞–Ω–∏—Ö
                    sample_data = df[col].dropna().head(3)
                    if len(sample_data) > 0:
                        print(f"   üìù –ü–†–ò–ö–õ–ê–î–ò –î–ê–ù–ò–•:")
                        for idx, text in enumerate(sample_data.values):
                            text_preview = str(text)[:200].replace('\n', ' ')
                            if len(str(text)) > 200:
                                text_preview += "..."
                            print(f"      {idx+1}. {text_preview}")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–≤–∂–∏–Ω–∏ —Ç–µ–∫—Å—Ç—É
                    text_lengths = df[col].dropna().str.len()
                    if len(text_lengths) > 0:
                        print(f"   üìè –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–≤–∂–∏–Ω–∏ —Ç–µ–∫—Å—Ç—É:")
                        print(f"      –ú—ñ–Ω: {text_lengths.min()} —Å–∏–º–≤–æ–ª—ñ–≤")
                        print(f"      –ú–∞–∫—Å: {text_lengths.max()} —Å–∏–º–≤–æ–ª—ñ–≤")
                        print(f"      –°–µ—Ä–µ–¥–Ω—è: {text_lengths.mean():.0f} —Å–∏–º–≤–æ–ª—ñ–≤")
                        print(f"      –ú–µ–¥—ñ–∞–Ω–∞: {text_lengths.median():.0f} —Å–∏–º–≤–æ–ª—ñ–≤")
            else:
                print("‚ùå –ö–æ–ª–æ–Ω–∫–∏ –∑ –ø—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è–º–∏ –ù–ï –ó–ù–ê–ô–î–ï–ù–û!")
                print("üîç –ú–æ–∂–ª–∏–≤–æ –ø—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è –≤ —ñ–Ω—à–∏—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö:")
                
                # –ü–æ–∫–∞–∑–∞—Ç–∏ –ø–µ—Ä—à—ñ 5 –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è –º–∞–Ω—É–∞–ª—å–Ω–æ–≥–æ –ø–æ—à—É–∫—É
                print("\nüìù –ü–µ—Ä—à—ñ 5 –∑–∞–ø–∏—Å—ñ–≤ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É:")
                sample_df = df.head(5)
                for col in df.columns:
                    print(f"\n   –ö–æ–ª–æ–Ω–∫–∞: {col}")
                    for idx, val in enumerate(sample_df[col]):
                        if pd.notna(val):
                            val_str = str(val)[:100]
                            if len(str(val)) > 100:
                                val_str += "..."
                            print(f"      –ó–∞–ø–∏—Å {idx+1}: {val_str}")
                        else:
                            print(f"      –ó–∞–ø–∏—Å {idx+1}: [–ü–£–°–¢–û]")
                        if idx >= 2:  # –ü–æ–∫–∞–∑–∞—Ç–∏ —Ç—ñ–ª—å–∫–∏ –ø–µ—Ä—à—ñ 3
                            break
            
            # –ü–æ—à—É–∫ –æ—Å–Ω–æ–≤–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫ (–Ω–∞–∑–≤–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç—É, –ø–æ–∫–∞–∑–∞–Ω–Ω—è, —Ç–æ—â–æ)
            print(f"\nüè• –ü–û–®–£–ö –û–°–ù–û–í–ù–ò–• –ú–ï–î–ò–ß–ù–ò–• –ö–û–õ–û–ù–û–ö:")
            medical_keywords = {
                '–Ω–∞–∑–≤–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç—É': ['–Ω–∞–∑–≤–∞', '–ø—Ä–µ–ø–∞—Ä–∞—Ç', 'drug', 'name', 'medicine'],
                '–ø–æ–∫–∞–∑–∞–Ω–Ω—è': ['–ø–æ–∫–∞–∑–∞–Ω–Ω—è', 'indication', '–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è', '–∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è'],
                '–¥–æ–∑—É–≤–∞–Ω–Ω—è': ['–¥–æ–∑–∞', '–¥–æ–∑—É–≤–∞–Ω–Ω—è', 'dosage', 'dose'],
                '—Ñ–∞—Ä–º–∞–∫–æ–ª–æ–≥—ñ—á–Ω–∞ –≥—Ä—É–ø–∞': ['—Ñ–∞—Ä–º–∞–∫–æ', '–≥—Ä—É–ø–∞', 'group', '–∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è']
            }
            
            found_medical_cols = {}
            for category, keywords in medical_keywords.items():
                for col in df.columns:
                    col_lower = col.lower()
                    for keyword in keywords:
                        if keyword in col_lower:
                            found_medical_cols[category] = col
                            break
                    if category in found_medical_cols:
                        break
            
            for category, col in found_medical_cols.items():
                non_null = df[col].notna().sum()
                percentage = (non_null / len(df)) * 100
                print(f"   ‚úÖ {category}: '{col}' ({non_null:,} –∑–∞–ø–∏—Å—ñ–≤, {percentage:.1f}%)")
            
        except Exception as e:
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª—ñ–∑—ñ {path}: {e}")
    
    print(f"\n{'='*60}")
    print("‚úÖ –ê–ù–ê–õ–Ü–ó –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"{'='*60}")

if __name__ == "__main__":
    analyze_dataset()