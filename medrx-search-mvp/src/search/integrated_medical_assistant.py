#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Integrated Medical Assistant with Gemini AI
–ë–∞–∑—É—î—Ç—å—Å—è –Ω–∞ –≤–∞—à–æ–º—É –≤—ñ–¥–º—ñ–Ω–Ω–æ–º—É hybrid search engine + –¥–æ–¥–∞—î Gemini –ø—Ä–∏—Ä–æ–¥–Ω–µ —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è
"""

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, CrossEncoder
from sentence_transformers.util import cos_sim
from rank_bm25 import BM25Okapi
from typing import List, Dict, Tuple, Optional, Any
import re
import argparse
from pathlib import Path
import json
import time
from collections import defaultdict
from dataclasses import dataclass
from datetime import datetime
import os
import sys

import google.generativeai as genai
from dotenv import load_dotenv

@dataclass
class ConversationMessage:
    """–ü–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –≤ —Ä–æ–∑–º–æ–≤—ñ"""
    role: str  # 'user' or 'assistant'
    content: str
    timestamp: datetime
    search_data: Optional[Dict] = None

class AdvancedMedicalSearchEngine:
    """
    Hybrid search –∑ BM25 + Vector + RRF + CrossEncoder
    (–í–∞—à –ø–µ—Ä–µ–≤—ñ—Ä–µ–Ω–∏–π —Ç–∞ –Ω–∞–¥—ñ–π–Ω–∏–π search engine)
    """
    
    def __init__(self, model_path: str, data_path: str, crossencoder_model: str = None):
        print("üîÑ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Advanced Medical Search Engine...")
        
        # Load models
        self.sentence_model = SentenceTransformer(model_path)
        self.crossencoder = CrossEncoder(
            crossencoder_model or 'cross-encoder/ms-marco-MiniLM-L-2-v2'
        ) if crossencoder_model != "none" else None
        
        # Load data
        self.df = pd.read_parquet(data_path)
        print(f"üìä –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {len(self.df)} –º–µ–¥–∏—á–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤")
        
        # Initialize search components
        self.documents = []
        self.doc_embeddings = None
        self.bm25_index = None
        self.contraindications_index = {}
        
        # Search statistics
        self.search_stats = {
            'total_searches': 0,
            'avg_bm25_time': 0,
            'avg_vector_time': 0,
            'avg_crossencoder_time': 0
        }
        
        self._prepare_search_indices()
    
    def _clean_text_for_bm25(self, text: str) -> List[str]:
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç—É –¥–ª—è BM25 tokenization"""
        if not isinstance(text, str):
            return []
        
        # –í–∏–¥–∞–ª–∏—Ç–∏ [SEP] —Ç–æ–∫–µ–Ω–∏ —Ç–∞ –æ—á–∏—Å—Ç–∏—Ç–∏
        text = text.replace('[SEP]', ' ')
        # Lowercase —Ç–∞ –≤–∏–¥–∞–ª–∏—Ç–∏ –∑–∞–π–≤—ñ —Å–∏–º–≤–æ–ª–∏
        text = re.sub(r'[^\w\s\-]', ' ', text.lower())
        # Tokenize
        tokens = text.split()
        # –í–∏–¥–∞–ª–∏—Ç–∏ –¥—É–∂–µ –∫–æ—Ä–æ—Ç–∫—ñ —Ç–æ–∫–µ–Ω–∏
        tokens = [token for token in tokens if len(token) > 2]
        
        return tokens
    
    def _prepare_search_indices(self):
        """–ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤—Å—ñ—Ö —ñ–Ω–¥–µ–∫—Å—ñ–≤ –¥–ª—è –ø–æ—à—É–∫—É"""
        print("üèóÔ∏è  –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —ñ–Ω–¥–µ–∫—Å—ñ–≤...")
        
        bm25_docs = []
        
        for idx, row in self.df.iterrows():
            # –°—Ç–≤–æ—Ä–∏—Ç–∏ –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø–æ—à—É–∫—É
            doc_parts = []
            contraindications = ""
            
            if pd.notna(row['–ù–∞–∑–≤–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç—É']):
                doc_parts.append(str(row['–ù–∞–∑–≤–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç—É']))
            
            if '–§–∞—Ä–º–∞–∫–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç–∏—á–Ω–∞ –≥—Ä—É–ø–∞' in row and pd.notna(row['–§–∞—Ä–º–∞–∫–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç–∏—á–Ω–∞ –≥—Ä—É–ø–∞']):
                group_text = str(row['–§–∞—Ä–º–∞–∫–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç–∏—á–Ω–∞ –≥—Ä—É–ø–∞'])[:200]
                doc_parts.append(group_text)
            
            if pd.notna(row['–ü–æ–∫–∞–∑–∞–Ω–Ω—è']):
                indications = str(row['–ü–æ–∫–∞–∑–∞–Ω–Ω—è'])[:800]
                doc_parts.append(indications)
            
            if '–ü—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è' in row and pd.notna(row['–ü—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è']):
                contraindications = str(row['–ü—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è'])[:500]
            
            # –î–æ–∫—É–º–µ–Ω—Ç –¥–ª—è vector search
            doc_text = ' [SEP] '.join(doc_parts)
            
            # –î–æ–∫—É–º–µ–Ω—Ç –¥–ª—è BM25 (–±–µ–∑ [SEP], –±—ñ–ª—å—à –ø—Ä–∏—Ä–æ–¥–Ω–∏–π)
            bm25_text = ' '.join(doc_parts)
            bm25_tokens = self._clean_text_for_bm25(bm25_text)
            
            self.documents.append({
                'id': idx,
                'text': doc_text,
                'bm25_text': bm25_text,
                'name': row['–ù–∞–∑–≤–∞ –ø—Ä–µ–ø–∞—Ä–∞—Ç—É'],
                'indications': row['–ü–æ–∫–∞–∑–∞–Ω–Ω—è'] if pd.notna(row['–ü–æ–∫–∞–∑–∞–Ω–Ω—è']) else "",
                'contraindications': contraindications,
                'therapeutic_group': row.get('–§–∞—Ä–º–∞–∫–æ—Ç–µ—Ä–∞–ø–µ–≤—Ç–∏—á–Ω–∞ –≥—Ä—É–ø–∞', ""),
                'side_effects': row.get('–ü–æ–±—ñ—á–Ω—ñ —Ä–µ–∞–∫—Ü—ñ—ó', "") if pd.notna(row.get('–ü–æ–±—ñ—á–Ω—ñ —Ä–µ–∞–∫—Ü—ñ—ó', "")) else "",
                'original_row': row
            })
            
            bm25_docs.append(bm25_tokens)
            self.contraindications_index[idx] = contraindications.lower()
        
        # –°—Ç–≤–æ—Ä–∏—Ç–∏ BM25 —ñ–Ω–¥–µ–∫—Å
        print("üîç –°—Ç–≤–æ—Ä–µ–Ω–Ω—è BM25 —ñ–Ω–¥–µ–∫—Å—É...")
        self.bm25_index = BM25Okapi(bm25_docs)
        
        # –°—Ç–≤–æ—Ä–∏—Ç–∏ vector —ñ–Ω–¥–µ–∫—Å
        print("üß† –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è embeddings...")
        doc_texts = [doc['text'] for doc in self.documents]
        self.doc_embeddings = self.sentence_model.encode(
            doc_texts, 
            show_progress_bar=True,
            batch_size=32
        )
        
        print("‚úÖ –í—Å—ñ —ñ–Ω–¥–µ–∫—Å–∏ –≥–æ—Ç–æ–≤—ñ!")
    
    def _bm25_search(self, query: str, top_k: int = 50) -> List[Tuple[int, float]]:
        """BM25 –ø–æ—à—É–∫"""
        start_time = time.time()
        
        query_tokens = self._clean_text_for_bm25(query)
        if not query_tokens:
            return []
        
        # BM25 scoring
        scores = self.bm25_index.get_scores(query_tokens)
        
        # –ù–æ—Ä–º–∞–ª—ñ–∑—É–≤–∞—Ç–∏ scores (0-1)
        if scores.max() > 0:
            scores = scores / scores.max()
        
        # –¢–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        top_indices = np.argsort(scores)[::-1][:top_k]
        results = [(int(idx), float(scores[idx])) for idx in top_indices if scores[idx] > 0]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        elapsed = time.time() - start_time
        self.search_stats['avg_bm25_time'] = (
            self.search_stats['avg_bm25_time'] * self.search_stats['total_searches'] + elapsed
        ) / (self.search_stats['total_searches'] + 1)
        
        return results
    
    def _vector_search(self, query: str, top_k: int = 50) -> List[Tuple[int, float]]:
        """Vector –ø–æ—à—É–∫"""
        start_time = time.time()
        
        # Encode query
        query_embedding = self.sentence_model.encode(query)
        
        # Compute similarities
        similarities = cos_sim(query_embedding, self.doc_embeddings)[0]
        
        # –¢–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
        top_indices = similarities.argsort(descending=True)[:top_k]
        results = [(int(idx), float(similarities[idx])) for idx in top_indices]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        elapsed = time.time() - start_time
        self.search_stats['avg_vector_time'] = (
            self.search_stats['avg_vector_time'] * self.search_stats['total_searches'] + elapsed
        ) / (self.search_stats['total_searches'] + 1)
        
        return results
    
    def _reciprocal_rank_fusion(self, bm25_results: List[Tuple[int, float]], 
                              vector_results: List[Tuple[int, float]], 
                              k: int = 60) -> List[Tuple[int, float]]:
        """Reciprocal Rank Fusion –¥–ª—è –æ–±'—î–¥–Ω–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤"""
        
        # –°—Ç–≤–æ—Ä–∏—Ç–∏ —Ä–∞–Ω–∫—ñ–Ω–≥–∏
        bm25_ranks = {doc_id: rank + 1 for rank, (doc_id, score) in enumerate(bm25_results)}
        vector_ranks = {doc_id: rank + 1 for rank, (doc_id, score) in enumerate(vector_results)}
        
        # –í—Å—ñ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –¥–æ–∫—É–º–µ–Ω—Ç–∏
        all_docs = set(bm25_ranks.keys()) | set(vector_ranks.keys())
        
        # RRF scoring
        rrf_scores = {}
        for doc_id in all_docs:
            rrf_score = 0
            if doc_id in bm25_ranks:
                rrf_score += 1 / (k + bm25_ranks[doc_id])
            if doc_id in vector_ranks:
                rrf_score += 1 / (k + vector_ranks[doc_id])
            
            rrf_scores[doc_id] = rrf_score
        
        # –°–æ—Ä—Ç—É–≤–∞—Ç–∏ –∑–∞ RRF score
        sorted_results = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)
        
        return sorted_results
    
    def _crossencoder_rerank(self, query: str, candidate_results: List[Tuple[int, float]], 
                           top_k: int = 10) -> List[Tuple[int, float]]:
        """CrossEncoder re-ranking"""
        if not self.crossencoder or len(candidate_results) == 0:
            return candidate_results[:top_k]
        
        start_time = time.time()
        
        # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –ø–∞—Ä–∏ query-document
        query_doc_pairs = []
        doc_ids = []
        
        for doc_id, _ in candidate_results[:20]:  # –û–±–º–µ–∂–∏—Ç–∏ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ
            doc_text = self.documents[doc_id]['bm25_text'][:500]  # Truncate for CrossEncoder
            query_doc_pairs.append([query, doc_text])
            doc_ids.append(doc_id)
        
        if not query_doc_pairs:
            return []
        
        # CrossEncoder scoring
        ce_scores = self.crossencoder.predict(query_doc_pairs)
        
        # –û–±'—î–¥–Ω–∞—Ç–∏ –∑ doc_ids —Ç–∞ —Å–æ—Ä—Ç—É–≤–∞—Ç–∏
        reranked = list(zip(doc_ids, ce_scores))
        reranked.sort(key=lambda x: x[1], reverse=True)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        elapsed = time.time() - start_time
        self.search_stats['avg_crossencoder_time'] = (
            self.search_stats['avg_crossencoder_time'] * self.search_stats['total_searches'] + elapsed
        ) / (self.search_stats['total_searches'] + 1)
        
        return reranked[:top_k]
    
    def _check_contraindications(self, query: str, doc_id: int) -> Dict[str, any]:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ø—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω—å"""
        contraindications = self.contraindications_index.get(doc_id, "")
        
        # –ü—Ä–æ—Å—Ç—ñ heuristics –¥–ª—è –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω—å
        warning_keywords = [
            '–≤–∞–≥—ñ—Ç–Ω—ñ—Å—Ç—å', '–≥–æ–¥—É–≤–∞–Ω–Ω—è –≥—Ä—É–¥–¥—é', '–¥—ñ—Ç–∏', '–ø–µ—á—ñ–Ω–∫–æ–≤–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—ñ—Å—Ç—å',
            '–Ω–∏—Ä–∫–æ–≤–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—ñ—Å—Ç—å', '—Å–µ—Ä—Ü–µ–≤–∞ –Ω–µ–¥–æ—Å—Ç–∞—Ç–Ω—ñ—Å—Ç—å', '–∞–ª–µ—Ä–≥—ñ—è'
        ]
        
        warnings = []
        for keyword in warning_keywords:
            if keyword in contraindications:
                warnings.append(keyword)
        
        return {
            'has_contraindications': len(contraindications) > 0,
            'warnings': warnings,
            'contraindications_text': contraindications[:200] + "..." if len(contraindications) > 200 else contraindications
        }
    
    def search(self, query: str, top_k: int = 5, use_crossencoder: bool = True,
               include_safety: bool = True, verbose: bool = False) -> Dict:
        """–ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –ø–æ—à—É–∫—É"""
        
        search_start = time.time()
        self.search_stats['total_searches'] += 1
        
        if verbose:
            print(f"üîç –ü–æ—à—É–∫: '{query}'")
        
        # Stage 1: BM25 Search
        if verbose:
            print("   üìù BM25 –ø–æ—à—É–∫...")
        bm25_results = self._bm25_search(query, top_k=50)
        
        # Stage 2: Vector Search  
        if verbose:
            print("   üß† Vector –ø–æ—à—É–∫...")
        vector_results = self._vector_search(query, top_k=50)
        
        # Stage 3: Reciprocal Rank Fusion
        if verbose:
            print("   üîÑ RRF –æ–±'—î–¥–Ω–∞–Ω–Ω—è...")
        rrf_results = self._reciprocal_rank_fusion(bm25_results, vector_results)
        
        # Stage 4: CrossEncoder Re-ranking
        if use_crossencoder and self.crossencoder:
            if verbose:
                print("   üéØ CrossEncoder re-ranking...")
            final_results = self._crossencoder_rerank(query, rrf_results, top_k=top_k)
        else:
            final_results = rrf_results[:top_k]
        
        # Stage 5: Prepare results with safety info
        search_results = []
        for doc_id, score in final_results:
            doc = self.documents[doc_id]
            
            result = {
                'rank': len(search_results) + 1,
                'drug_name': doc['name'],
                'score': float(score),
                'indications': doc['indications'][:300] + "..." if len(doc['indications']) > 300 else doc['indications'],
                'therapeutic_group': doc['therapeutic_group'][:100] if doc['therapeutic_group'] else "",
                'side_effects': doc['side_effects'][:300] + "..." if len(doc['side_effects']) > 300 else doc['side_effects']
            }
            
            # –î–æ–¥–∞—Ç–∏ safety information
            if include_safety:
                safety_info = self._check_contraindications(query, doc_id)
                result['safety'] = safety_info
            
            search_results.append(result)
        
        total_time = time.time() - search_start
        
        return {
            'query': query,
            'results': search_results,
            'search_info': {
                'total_time': f"{total_time:.3f}s",
                'bm25_candidates': len(bm25_results),
                'vector_candidates': len(vector_results),
                'rrf_candidates': len(rrf_results),
                'final_results': len(final_results),
                'used_crossencoder': use_crossencoder and self.crossencoder is not None
            },
            'disclaimer': "‚ö†Ô∏è  –ó–∞–≤–∂–¥–∏ –∫–æ–Ω—Å—É–ª—å—Ç—É–π—Ç–µ—Å—å –∑ –ª—ñ–∫–∞—Ä–µ–º –ø–µ—Ä–µ–¥ –ø—Ä–∏–π–æ–º–æ–º –ª—ñ–∫—ñ–≤"
        }
    
    def get_search_statistics(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—à—É–∫—É"""
        return {
            'total_searches': self.search_stats['total_searches'],
            'avg_times': {
                'bm25': f"{self.search_stats['avg_bm25_time']:.4f}s",
                'vector': f"{self.search_stats['avg_vector_time']:.4f}s", 
                'crossencoder': f"{self.search_stats['avg_crossencoder_time']:.4f}s"
            },
            'index_info': {
                'total_documents': len(self.documents),
                'embedding_dimension': self.doc_embeddings.shape[1] if self.doc_embeddings is not None else 0,
                'has_crossencoder': self.crossencoder is not None
            }
        }

class GeminiMedicalAssistant:
    """
    Gemini AI Assistant –ø–æ–≤–µ—Ä—Ö –≤–∞—à–æ–≥–æ –Ω–∞–¥—ñ–π–Ω–æ–≥–æ hybrid search engine
    """
    
    def __init__(self, gemini_api_key: str, search_engine: AdvancedMedicalSearchEngine):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞
        
        Args:
            gemini_api_key: API –∫–ª—é—á –¥–ª—è Gemini
            search_engine: –í–∞—à –Ω–∞–¥—ñ–π–Ω–∏–π hybrid search engine
        """
        print("ü§ñ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è Gemini Medical Assistant...")
        
        # Configure Gemini
        genai.configure(api_key=gemini_api_key)
        self.model = genai.GenerativeModel('gemini-1.5-flash')
        
        # Search engine
        self.search_engine = search_engine
        
        # Conversation history
        self.conversation_history: List[ConversationMessage] = []
        
        print("‚úÖ Gemini Medical Assistant –≥–æ—Ç–æ–≤–∏–π!")
    
    def enhance_user_query(self, user_query: str) -> str:
        """
        –ü–æ–∫—Ä–∞—â–∏—Ç–∏ –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –¥–ª—è –∫—Ä–∞—â–æ–≥–æ –ø–æ—à—É–∫—É
        """
        enhancement_prompt = f"""
–¢–∏ - –º–µ–¥–∏—á–Ω–∏–π –µ–∫—Å–ø–µ—Ä—Ç. –ü–µ—Ä–µ—Ç–≤–æ—Ä–∏ –∑–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –≤ –æ–ø—Ç–∏–º–∞–ª—å–Ω–∏–π –ø–æ—à—É–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç –¥–ª—è –∑–Ω–∞—Ö–æ–¥–∂–µ–Ω–Ω—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –º–µ–¥–∏—á–Ω–∏—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç—ñ–≤.

–ü—Ä–∞–≤–∏–ª–∞:
1. –í–∏—Ç—è–≥–Ω–∏ –≥–æ–ª–æ–≤–Ω—ñ –º–µ–¥–∏—á–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏ (–∑–∞—Ö–≤–æ—Ä—é–≤–∞–Ω–Ω—è, —Å–∏–º–ø—Ç–æ–º–∏)
2. –î–æ–¥–∞–π —Å–∏–Ω–æ–Ω—ñ–º–∏ —Ç–∞ –º–µ–¥–∏—á–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏
3. –í–∏–¥–∞–ª–∏ –∑–∞–π–≤—ñ —Å–ª–æ–≤–∞ ("–ø–æ—Ä–∞–¥—å—Ç–µ", "—Å–∫–∞–∂—ñ—Ç—å", "–¥–æ–ø–æ–º–æ–∂—ñ—Ç—å")
4. –ó–∞–ª–∏—à–∏ –ª–∏—à–µ –∫–ª—é—á–æ–≤—ñ –º–µ–¥–∏—á–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏
5. –ü–∏—à–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é

–ü—Ä–∏–∫–ª–∞–¥–∏:
"–ü–æ—Ä–∞–¥—å—Ç–µ –ø—Ä–µ–ø–∞—Ä–∞—Ç –≤—ñ–¥ –¥—ñ–∞—Ä–µ—ó" ‚Üí "–¥—ñ–∞—Ä–µ—è –ª—ñ–∫—É–≤–∞–Ω–Ω—è –ø—Ä–æ—Ç–∏–¥—ñ–∞—Ä–µ–π–Ω—ñ –∑–∞—Å–æ–±–∏"
"–©–æ –ø—Ä–∏–π–º–∞—Ç–∏ –≤—ñ–¥ –≤–∏—Å–æ–∫–æ–≥–æ —Ç–∏—Å–∫—É?" ‚Üí "–∞—Ä—Ç–µ—Ä—ñ–∞–ª—å–Ω–∞ –≥—ñ–ø–µ—Ä—Ç–µ–Ω–∑—ñ—è –≥—ñ–ø–µ—Ä—Ç–æ–Ω—ñ—è –ª—ñ–∫—É–≤–∞–Ω–Ω—è"
"–î–æ–ø–æ–º–æ–∂—ñ—Ç—å –∑ –±–æ–ª–µ–º –≤ –∂–∏–≤–æ—Ç—ñ" ‚Üí "–±—ñ–ª—å –∂–∏–≤–æ—Ç —à–ª—É–Ω–æ–∫ —Å–ø–∞–∑–º"
"–ß–∏–º –ª—ñ–∫—É–≤–∞—Ç–∏ –∑–∞—Å—Ç—É–¥—É?" ‚Üí "–∑–∞—Å—Ç—É–¥–∞ –ì–†–í–Ü –≤—ñ—Ä—É—Å–Ω–∞ —ñ–Ω—Ñ–µ–∫—Ü—ñ—è –ª—ñ–∫—É–≤–∞–Ω–Ω—è"

–ó–∞–ø–∏—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞: "{user_query}"

–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π –ø–æ—à—É–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç (—Ç—ñ–ª—å–∫–∏ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞):"""

        try:
            response = self.model.generate_content(enhancement_prompt)
            enhanced_query = response.text.strip()
            
            print(f"üîç –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–∏–π –∑–∞–ø–∏—Ç: '{user_query}'")
            print(f"üéØ –ü–æ–∫—Ä–∞—â–µ–Ω–∏–π –∑–∞–ø–∏—Ç: '{enhanced_query}'")
            
            return enhanced_query
        except Exception as e:
            print(f"‚ö†Ô∏è  –ü–æ–º–∏–ª–∫–∞ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –∑–∞–ø–∏—Ç—É: {e}")
            return user_query
    
    def generate_medical_response(self, user_query: str, search_results: Dict, 
                                user_profile: Optional[Dict] = None) -> str:
        """
        –ì–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –ø—Ä–∏—Ä–æ–¥–Ω–æ–º–æ–≤–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–æ—à—É–∫—É
        """
        
        # –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ –ø—Ä–æ –∑–Ω–∞–π–¥–µ–Ω—ñ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∏
        medications_info = ""
        if search_results['results']:
            medications_info = "–ó–ù–ê–ô–î–ï–ù–Ü –ü–†–ï–ü–ê–†–ê–¢–ò:\n"
            for i, result in enumerate(search_results['results'], 1):
                medications_info += f"""
{i}. –ü–†–ï–ü–ê–†–ê–¢: {result['drug_name']}
   –ü–û–ö–ê–ó–ê–ù–ù–Ø: {result['indications']}
   –§–ê–†–ú–ì–†–£–ü–ê: {result.get('therapeutic_group', '–ù–µ –≤–∫–∞–∑–∞–Ω–æ')}"""
                
                if 'safety' in result:
                    safety = result['safety']
                    if safety['contraindications_text']:
                        medications_info += f"\n   –ü–†–û–¢–ò–ü–û–ö–ê–ó–ê–ù–ù–Ø: {safety['contraindications_text']}"
                    if safety['warnings']:
                        medications_info += f"\n   –ü–û–ü–ï–†–ï–î–ñ–ï–ù–ù–Ø: {', '.join(safety['warnings'])}"
                
                if result.get('side_effects'):
                    medications_info += f"\n   –ü–û–ë–Ü–ß–ù–Ü –ï–§–ï–ö–¢–ò: {result['side_effects']}"
                
                medications_info += "\n"
        else:
            medications_info = "–ù–ï –ó–ù–ê–ô–î–ï–ù–û –†–ï–õ–ï–í–ê–ù–¢–ù–ò–• –ü–†–ï–ü–ê–†–ê–¢–Ü–í"
        
        # –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø—Ä–æ—Ñ—ñ–ª—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        profile_info = ""
        if user_profile:
            profile_info = f"""
–ü–†–û–§–Ü–õ–¨ –ö–û–†–ò–°–¢–£–í–ê–ß–ê:
- –•—Ä–æ–Ω—ñ—á–Ω—ñ –∑–∞—Ö–≤–æ—Ä—é–≤–∞–Ω–Ω—è: {user_profile.get('chronic_conditions', '–ù–µ –≤–∫–∞–∑–∞–Ω–æ')}
- –ê–ª–µ—Ä–≥—ñ—ó: {user_profile.get('allergies', '–ù–µ –≤–∫–∞–∑–∞–Ω–æ')}
- –í—ñ–∫: {user_profile.get('age', '–ù–µ –≤–∫–∞–∑–∞–Ω–æ')}
- –°—Ç–∞—Ç—å: {user_profile.get('gender', '–ù–µ –≤–∫–∞–∑–∞–Ω–æ')}
"""
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ–ø–µ—Ä–µ–¥–Ω—ñ—Ö –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
        context = ""
        if self.conversation_history:
            context = "–ö–û–ù–¢–ï–ö–°–¢ –†–û–ó–ú–û–í–ò:\n"
            for msg in self.conversation_history[-3:]:  # –û—Å—Ç–∞–Ω–Ω—ñ 3 –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
                context += f"- {msg.role}: {msg.content[:100]}...\n"
        
        # –ì–æ–ª–æ–≤–Ω–∏–π –ø—Ä–æ–º–ø—Ç –¥–ª—è Gemini
        medical_prompt = f"""–¢–∏ - –¥–æ—Å–≤—ñ–¥—á–µ–Ω–∏–π –º–µ–¥–∏—á–Ω–∏–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Ç–∞ —Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –Ω–∞–¥–∞—Ç–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–≤—ñ –∑—Ä–æ–∑—É–º—ñ–ª—É, –∫–æ—Ä–∏—Å–Ω—É —Ç–∞ –±–µ–∑–ø–µ—á–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –º–µ–¥–∏—á–Ω—ñ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∏.

{context}

{profile_info}

–ó–ê–ü–ò–¢ –ö–û–†–ò–°–¢–£–í–ê–ß–ê: "{user_query}"

{medications_info}

–Ü–ù–°–¢–†–£–ö–¶–Ü–á –î–õ–Ø –í–Ü–î–ü–û–í–Ü–î–Ü:

1. –ü–†–ò–†–û–î–ù–ï –°–ü–Ü–õ–ö–£–í–ê–ù–ù–Ø:
   - –°–ø—ñ–ª–∫—É–π—Å—è —Ç–µ–ø–ª–æ —Ç–∞ –∑ —Ä–æ–∑—É–º—ñ–Ω–Ω—è–º
   - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –ø—Ä–æ—Å—Ç—ñ, –∑—Ä–æ–∑—É–º—ñ–ª—ñ —Ç–µ—Ä–º—ñ–Ω–∏
   - –ë—É–¥—å –µ–º–ø–∞—Ç–∏—á–Ω–∏–º –¥–æ –ø—Ä–æ–±–ª–µ–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞

2. –°–¢–†–£–ö–¢–£–†–ê –í–Ü–î–ü–û–í–Ü–î–Ü:
   - –ü–æ—á–Ω–∏ –∑ —Ä–æ–∑—É–º—ñ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
   - –ü–æ—è—Å–Ω–∏ –∑–Ω–∞–π–¥–µ–Ω—ñ –ø—Ä–µ–ø–∞—Ä–∞—Ç–∏ –ø—Ä–æ—Å—Ç–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
   - –û–±–æ–≤'—è–∑–∫–æ–≤–æ —Ä–æ–∑–∫–∞–∂–∏ –ø—Ä–æ –ø—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è —Ç–∞ –ø–æ–±—ñ—á–Ω—ñ –µ—Ñ–µ–∫—Ç–∏
   - –î–∞–π –ø—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø–æ—Ä–∞–¥–∏

3. –ë–ï–ó–ü–ï–ö–ê:
   - –ó–ê–í–ñ–î–ò –Ω–∞–≥–æ–ª–æ—à—É–π –Ω–∞ –Ω–µ–æ–±—Ö—ñ–¥–Ω–æ—Å—Ç—ñ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—ó –∑ –ª—ñ–∫–∞—Ä–µ–º
   - –Ø–∫—â–æ —î –∫–æ–Ω—Ñ–ª—ñ–∫—Ç–∏ –∑ –ø—Ä–æ—Ñ—ñ–ª–µ–º –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ - –æ–±–æ–≤'—è–∑–∫–æ–≤–æ –ø–æ–ø–µ—Ä–µ–¥–∏
   - –ù–µ –¥—ñ–∞–≥–Ω–æ—Å—Ç—É–π —Ç–∞ –Ω–µ –ø—Ä–∏–∑–Ω–∞—á–∞–π –ª—ñ–∫—É–≤–∞–Ω–Ω—è
   - –ü–æ—è—Å–Ω—é–π —Ä–∏–∑–∏–∫–∏ —Ç–∞ –æ–±–º–µ–∂–µ–Ω–Ω—è

4. –Ø–ö–©–û –ü–†–ï–ü–ê–†–ê–¢–Ü–í –ù–ï –ó–ù–ê–ô–î–ï–ù–û:
   - –ü–æ—è—Å–Ω–∏ –º–æ–∂–ª–∏–≤—ñ –ø—Ä–∏—á–∏–Ω–∏
   - –î–∞–π –∑–∞–≥–∞–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
   - –ù–∞–≥–æ–ª–æ—Å–∏ –Ω–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—ó –∑ –ª—ñ–∫–∞—Ä–µ–º
   - –ó–∞–ø—Ä–æ–ø–æ–Ω—É–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ –¥—ñ—ó

5. –ú–û–í–ê:
   - –ü–∏—à–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é
   - –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π –º–µ–¥–∏—á–Ω—É —Ç–µ—Ä–º—ñ–Ω–æ–ª–æ–≥—ñ—é –∫–æ–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω–æ, –∞–ª–µ –∑ –ø–æ—è—Å–Ω–µ–Ω–Ω—è–º–∏
   - –ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–º —Ç–∞ –∫–æ—Ä–∏—Å–Ω–∏–º

–°—Ç–≤–æ—Ä–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥—å, —è–∫–∞ —Å–ø—Ä–∞–≤–¥—ñ –¥–æ–ø–æ–º–æ–∂–µ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–≤—ñ —Ç–∞ –∑–∞–±–µ–∑–ø–µ—á–∏—Ç—å –π–æ–≥–æ –±–µ–∑–ø–µ–∫—É:"""

        try:
            response = self.model.generate_content(medical_prompt)
            return response.text.strip()
        except Exception as e:
            return f"‚ùå –í–∏–±–∞—á—Ç–µ, –≤–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ: {e}\n\n–ü—Ä–æ—Ç–µ —è –∑–Ω–∞–π—à–æ–≤ –Ω–∞—Å—Ç—É–ø–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é:\n{self._format_basic_results(search_results)}"
    
    def _format_basic_results(self, search_results: Dict) -> str:
        """–ë–∞–∑–æ–≤–µ —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ —è–∫—â–æ Gemini –Ω–µ –ø—Ä–∞—Ü—é—î"""
        if not search_results['results']:
            return "‚ùå –ù–∞ –∂–∞–ª—å, –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç—ñ–≤ –¥–ª—è –≤–∞—à–æ–≥–æ –∑–∞–ø–∏—Ç—É."
        
        formatted = "üíä –ó–ù–ê–ô–î–ï–ù–Ü –ü–†–ï–ü–ê–†–ê–¢–ò:\n\n"
        for i, result in enumerate(search_results['results'], 1):
            formatted += f"{i}. {result['drug_name']}\n"
            formatted += f"   üìù –ü–æ–∫–∞–∑–∞–Ω–Ω—è: {result['indications']}\n"
            
            if 'safety' in result and result['safety']['contraindications_text']:
                formatted += f"   ‚ö†Ô∏è  –ü—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è: {result['safety']['contraindications_text']}\n"
            
            formatted += "\n"
        
        formatted += "‚ö†Ô∏è  –í–ê–ñ–õ–ò–í–û: –û–±–æ–≤'—è–∑–∫–æ–≤–æ –ø—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç—É–π—Ç–µ—Å—è –∑ –ª—ñ–∫–∞—Ä–µ–º –ø–µ—Ä–µ–¥ –ø—Ä–∏–π–æ–º–æ–º –±—É–¥—å-—è–∫–∏—Ö –ª—ñ–∫—ñ–≤!"
        return formatted
    
    def chat(self, user_message: str, user_profile: Optional[Dict] = None) -> str:
        """
        –ì–æ–ª–æ–≤–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è —Å–ø—ñ–ª–∫—É–≤–∞–Ω–Ω—è –∑ –∞—Å–∏—Å—Ç–µ–Ω—Ç–æ–º
        """
        print(f"\nüó£Ô∏è  –ö–æ—Ä–∏—Å—Ç—É–≤–∞—á: {user_message}")
        
        try:
            # 1. –ü–æ–∫—Ä–∞—â–∏—Ç–∏ –∑–∞–ø–∏—Ç
            enhanced_query = self.enhance_user_query(user_message)
            
            # 2. –ü–æ—à—É–∫ –ø—Ä–µ–ø–∞—Ä–∞—Ç—ñ–≤ (–∑ –≤–∞—à–∏–º –Ω–∞–¥—ñ–π–Ω–∏–º search engine!)
            print("üîç –ü–æ—à—É–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö –ø—Ä–µ–ø–∞—Ä–∞—Ç—ñ–≤...")
            search_results = self.search_engine.search(
                enhanced_query, 
                top_k=5,
                use_crossencoder=True,
                include_safety=True,
                verbose=False
            )
            
            # 3. –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –ø—Ä–∏—Ä–æ–¥–Ω–æ–º–æ–≤–Ω–æ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ
            print("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ...")
            response = self.generate_medical_response(
                user_message, 
                search_results, 
                user_profile
            )
            
            # 4. –ó–±–µ—Ä–µ–≥—Ç–∏ –≤ —ñ—Å—Ç–æ—Ä—ñ—ó
            user_msg = ConversationMessage(
                role='user',
                content=user_message,
                timestamp=datetime.now()
            )
            
            assistant_msg = ConversationMessage(
                role='assistant',
                content=response,
                timestamp=datetime.now(),
                search_data=search_results
            )
            
            self.conversation_history.extend([user_msg, assistant_msg])
            
            print(f"ü§ñ –ê—Å–∏—Å—Ç–µ–Ω—Ç –≤—ñ–¥–ø–æ–≤—ñ–≤!")
            return response
            
        except Exception as e:
            error_response = f"‚ùå –í–∏–±–∞—á—Ç–µ, –≤–∏–Ω–∏–∫–ª–∞ –ø–æ–º–∏–ª–∫–∞: {e}\n\nüí° –°–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª—é–≤–∞—Ç–∏ –≤–∞—à –∑–∞–ø–∏—Ç –∞–±–æ –∑–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ –ª—ñ–∫–∞—Ä—è."
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            return error_response
    
    def get_conversation_summary(self) -> Dict:
        """–û—Ç—Ä–∏–º–∞—Ç–∏ –ø—ñ–¥—Å—É–º–æ–∫ —Ä–æ–∑–º–æ–≤–∏"""
        return {
            'total_messages': len(self.conversation_history),
            'conversation_start': self.conversation_history[0].timestamp.isoformat() if self.conversation_history else None,
            'last_message': self.conversation_history[-1].timestamp.isoformat() if self.conversation_history else None,
            'topics_discussed': len(set(msg.search_data['query'] for msg in self.conversation_history if msg.search_data))
        }

def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    parser = argparse.ArgumentParser(description="Integrated Medical Assistant with Gemini")
    parser.add_argument("--model", default="../../models/medical-search-ua-full", 
                       help="Path to fine-tuned model")
    parser.add_argument("--data", default="../../data/processed/clean_medical.parquet",
                       help="Path to medical data")
    parser.add_argument("--env", default="../../.env", 
                       help="Path to .env file")
    parser.add_argument("--mode", default="assistant", choices=["assistant", "search"],
                       help="Mode: assistant (with Gemini) or search (original)")
    
    args = parser.parse_args()
    
    # Load environment variables
    load_dotenv(args.env)
    
    # Initialize search engine (–≤–∞—à –Ω–∞–¥—ñ–π–Ω–∏–π –¥–≤–∏–∂–æ–∫)
    print("üîÑ –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–∞—à–æ–≥–æ –Ω–∞–¥—ñ–π–Ω–æ–≥–æ hybrid search engine...")
    search_engine = AdvancedMedicalSearchEngine(
        model_path=args.model,
        data_path=args.data,
        crossencoder_model=os.getenv('CROSSENCODER_MODEL', 'cross-encoder/ms-marco-MiniLM-L-2-v2')
    )
    
    if args.mode == "search":
        # –†–µ–∂–∏–º –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –ø–æ—à—É–∫—É
        print("\nüîç –†–ï–ñ–ò–ú –û–†–ò–ì–Ü–ù–ê–õ–¨–ù–û–ì–û –ü–û–®–£–ö–£")
        print("–í–≤–µ–¥—ñ—Ç—å 'exit' –¥–ª—è –≤–∏—Ö–æ–¥—É, 'stats' –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
        
        while True:
            user_input = input("\nüîç –í–≤–µ–¥—ñ—Ç—å –∑–∞–ø–∏—Ç: ").strip()
            
            if user_input.lower() in ['exit', 'quit', '–≤–∏—Ö—ñ–¥']:
                break
            
            if user_input.lower() == 'stats':
                stats = search_engine.get_search_statistics()
                print(json.dumps(stats, indent=2, ensure_ascii=False))
                continue
            
            if not user_input:
                continue
            
            # –ü–æ—à—É–∫
            search_results = search_engine.search(user_input, verbose=True)
            
            # –ü–æ–∫–∞–∑–∞—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
            print(f"\n{'='*60}")
            print(f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –¥–ª—è: '{search_results['query']}'")
            print(f"{'='*60}")
            
            for result in search_results['results']:
                print(f"\n{result['rank']}. üíä {result['drug_name']}")
                print(f"   üìà –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å: {result['score']:.3f}")
                print(f"   üè• –ü–æ–∫–∞–∑–∞–Ω–Ω—è: {result['indications']}")
                
                if 'safety' in result and result['safety']['contraindications_text']:
                    print(f"   üö´ –ü—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è: {result['safety']['contraindications_text']}")
        
        return
    
    # –†–µ–∂–∏–º –∞—Å–∏—Å—Ç–µ–Ω—Ç–∞ –∑ Gemini
    gemini_api_key = os.getenv('GEMINI_API_KEY')
    
    if not gemini_api_key or gemini_api_key == 'your_actual_gemini_api_key_here':
        print("‚ùå –ü–æ–º–∏–ª–∫–∞: GEMINI_API_KEY –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∞–±–æ –Ω–µ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ –≤ .env —Ñ–∞–π–ª—ñ")
        print("üìù –ë—É–¥—å –ª–∞—Å–∫–∞, –≤—Å—Ç–∞–Ω–æ–≤—ñ—Ç—å –≤–∞—à —Å–ø—Ä–∞–≤–∂–Ω—ñ–π API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª—ñ")
        return
    
    # Initialize assistant
    assistant = GeminiMedicalAssistant(gemini_api_key, search_engine)
    
    # Interactive chat
    print("\n" + "="*60)
    print("üè• GEMINI MEDICAL ASSISTANT")
    print("üí¨ –†–æ–∑–º–æ–≤–ª—è–π—Ç–µ –ø—Ä–∏—Ä–æ–¥–Ω–æ—é –º–æ–≤–æ—é –ø—Ä–æ –º–µ–¥–∏—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏")
    print("üìù –í–≤–µ–¥—ñ—Ç—å 'exit' –¥–ª—è –≤–∏—Ö–æ–¥—É, 'summary' –¥–ª—è –ø—ñ–¥—Å—É–º–∫—É —Ä–æ–∑–º–æ–≤–∏")
    print("‚ö†Ô∏è  –í–ê–ñ–õ–ò–í–û: –¶–µ –ª–∏—à–µ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ–π–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç, –Ω–µ –∑–∞–º—ñ–Ω—é—î –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü—ñ—é –ª—ñ–∫–∞—Ä—è!")
    print("="*60)
    
    # Optional user profile
    user_profile = None
    setup_profile = input("\n‚ùì –ë–∞–∂–∞—î—Ç–µ –Ω–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ –º–µ–¥–∏—á–Ω–∏–π –ø—Ä–æ—Ñ—ñ–ª—å? (y/n): ").strip().lower()
    if setup_profile == 'y':
        user_profile = {}
        user_profile['age'] = input("üéÇ –í—ñ–∫: ").strip() or "–ù–µ –≤–∫–∞–∑–∞–Ω–æ"
        user_profile['gender'] = input("üë§ –°—Ç–∞—Ç—å (–ú/–ñ): ").strip() or "–ù–µ –≤–∫–∞–∑–∞–Ω–æ" 
        user_profile['chronic_conditions'] = input("üè• –•—Ä–æ–Ω—ñ—á–Ω—ñ –∑–∞—Ö–≤–æ—Ä—é–≤–∞–Ω–Ω—è (—á–µ—Ä–µ–∑ –∫–æ–º—É): ").strip() or "–ù–µ–º–∞—î"
        user_profile['allergies'] = input("‚ö†Ô∏è  –ê–ª–µ—Ä–≥—ñ—ó (—á–µ—Ä–µ–∑ –∫–æ–º—É): ").strip() or "–ù–µ–º–∞—î"
        print("‚úÖ –ü—Ä–æ—Ñ—ñ–ª—å —Å—Ç–≤–æ—Ä–µ–Ω–æ!")
    
    # Chat loop
    while True:
        try:
            user_input = input(f"\nüí¨ –í–∏: ").strip()
            
            if user_input.lower() in ['exit', 'quit', '–≤–∏—Ö—ñ–¥']:
                print("üëã –î–æ –∑—É—Å—Ç—Ä—ñ—á—ñ! –ë—É–¥—å—Ç–µ –∑–¥–æ—Ä–æ–≤—ñ!")
                break
            
            if user_input.lower() in ['summary', '–ø—ñ–¥—Å—É–º–æ–∫']:
                summary = assistant.get_conversation_summary()
                print(f"\nüìä –ü–Ü–î–°–£–ú–û–ö –†–û–ó–ú–û–í–ò:")
                print(json.dumps(summary, indent=2, ensure_ascii=False))
                continue
            
            if not user_input:
                continue
            
            # Get response from assistant
            response = assistant.chat(user_input, user_profile)
            print(f"\nü§ñ –ú–µ–¥–∏—á–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç:\n{response}")
            
        except KeyboardInterrupt:
            print("\nüëã –î–æ –∑—É—Å—Ç—Ä—ñ—á—ñ! –ë—É–¥—å—Ç–µ –∑–¥–æ—Ä–æ–≤—ñ!")
            break
        except Exception as e:
            print(f"\n‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")

if __name__ == "__main__":
    main()